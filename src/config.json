{
    "pipeline_kwargs":{
        "task":  "text-generation",
        "model": "meta-llama/Meta-Llama-3.1-8B-Instruct"
    },
    "generate_kwargs": {
        "return_full_text": false,
        "do_sample":        true,
        "temperature":      0.7,
        "max_new_tokens":   200,
        "top_p":            0.5
    },
    "gpus":     "2,3,4,5,6,7"
}