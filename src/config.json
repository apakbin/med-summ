{
    "pipeline_kwargs":{
        "task":  "text-generation",
        "model": "meta-llama/Meta-Llama-3.1-8B-Instruct"
    },
    "generate_kwargs": {
        "return_full_text": false,
        "do_sample":        true,
        "temperature":      0.1,
        "max_new_tokens":   1000,
        "top_p":            0.5
    },
    "gpus":     "0,1,2"
}